{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOzlYeC8pg1S",
        "outputId": "f7175711-5f19-4184-db99-70f357632ff2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "4+5\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Z7Dqm3phn5",
        "outputId": "c64aeb8e-94f4-4b5d-8748-b7383564514d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\"In the heart of a bustling metropolis lies a neighborhood where time seems to stand still. Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills. Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.\n",
        "\n",
        "In this enclave of tranquility, the aroma of freshly baked bread mingles with the scent of blooming jasmine, inviting passersby to pause and savor the simple pleasures. Narrow alleyways beckon the curious to explore hidden courtyards adorned with ivy-covered walls, where sunlight filters through ancient trees, casting dappled shadows on weathered cobblestones.\n",
        "\n",
        "Within this enclave, a vibrant tapestry of cultures intertwines, echoing the harmonious coexistence of its diverse inhabitants. Here, neighbors greet each other with warm smiles and gestures of goodwill, fostering a sense of community that transcends boundaries of age, ethnicity, and creed.\n",
        "\n",
        "As day turns to dusk, the neighborhood comes alive with the gentle hum of conversation and laughter drifting from sidewalk cafes and corner taverns. Against the backdrop of a painted sky ablaze with hues of orange and pink, residents gather to share stories and laughter, finding solace in the simple joys of human connection.\n",
        "\n",
        "In this hidden gem within the city's embrace, time slows to a gentle rhythm, offering sanctuary to weary souls seeking refuge from the frenetic pace of modern life. Amidst the chaos of the world beyond its borders, this neighborhood remains a beacon of serenity, a testament to the enduring power of community and the timeless beauty of human connection\"\"\""
      ],
      "metadata": {
        "id": "nosPxM2OpqEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "sentences = sent_tokenize(corpus)\n",
        "print(sentences)\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTdBMph5qBD5",
        "outputId": "a0e097c5-51c3-4fdc-9449-c0a2cb2979ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In the heart of a bustling metropolis lies a neighborhood where time seems to stand still.', 'Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills.', 'Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.', 'In this enclave of tranquility, the aroma of freshly baked bread mingles with the scent of blooming jasmine, inviting passersby to pause and savor the simple pleasures.', 'Narrow alleyways beckon the curious to explore hidden courtyards adorned with ivy-covered walls, where sunlight filters through ancient trees, casting dappled shadows on weathered cobblestones.', 'Within this enclave, a vibrant tapestry of cultures intertwines, echoing the harmonious coexistence of its diverse inhabitants.', 'Here, neighbors greet each other with warm smiles and gestures of goodwill, fostering a sense of community that transcends boundaries of age, ethnicity, and creed.', 'As day turns to dusk, the neighborhood comes alive with the gentle hum of conversation and laughter drifting from sidewalk cafes and corner taverns.', 'Against the backdrop of a painted sky ablaze with hues of orange and pink, residents gather to share stories and laughter, finding solace in the simple joys of human connection.', \"In this hidden gem within the city's embrace, time slows to a gentle rhythm, offering sanctuary to weary souls seeking refuge from the frenetic pace of modern life.\", 'Amidst the chaos of the world beyond its borders, this neighborhood remains a beacon of serenity, a testament to the enduring power of community and the timeless beauty of human connection']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences, 1):\n",
        "    print(f\"Sentence {i}: {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ICOtDBqyxL",
        "outputId": "a015dcec-b61c-471e-9bdc-81cfa9007800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: In the heart of a bustling metropolis lies a neighborhood where time seems to stand still.\n",
            "Sentence 2: Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills.\n",
            "Sentence 3: Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.\n",
            "Sentence 4: In this enclave of tranquility, the aroma of freshly baked bread mingles with the scent of blooming jasmine, inviting passersby to pause and savor the simple pleasures.\n",
            "Sentence 5: Narrow alleyways beckon the curious to explore hidden courtyards adorned with ivy-covered walls, where sunlight filters through ancient trees, casting dappled shadows on weathered cobblestones.\n",
            "Sentence 6: Within this enclave, a vibrant tapestry of cultures intertwines, echoing the harmonious coexistence of its diverse inhabitants.\n",
            "Sentence 7: Here, neighbors greet each other with warm smiles and gestures of goodwill, fostering a sense of community that transcends boundaries of age, ethnicity, and creed.\n",
            "Sentence 8: As day turns to dusk, the neighborhood comes alive with the gentle hum of conversation and laughter drifting from sidewalk cafes and corner taverns.\n",
            "Sentence 9: Against the backdrop of a painted sky ablaze with hues of orange and pink, residents gather to share stories and laughter, finding solace in the simple joys of human connection.\n",
            "Sentence 10: In this hidden gem within the city's embrace, time slows to a gentle rhythm, offering sanctuary to weary souls seeking refuge from the frenetic pace of modern life.\n",
            "Sentence 11: Amidst the chaos of the world beyond its borders, this neighborhood remains a beacon of serenity, a testament to the enduring power of community and the timeless beauty of human connection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = [word_tokenize(sentence) for sentence in sentences]\n",
        "for i, word in enumerate(word, 1):\n",
        "    print(f\"Sentence {i} tokens:\", word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhB5kcHOrptW",
        "outputId": "3c8e9c86-4f0a-423c-f7f0-c6664d032044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 tokens: ['In', 'the', 'heart', 'of', 'a', 'bustling', 'metropolis', 'lies', 'a', 'neighborhood', 'where', 'time', 'seems', 'to', 'stand', 'still', '.']\n",
            "Sentence 2 tokens: ['Here', ',', 'cobblestone', 'streets', 'wind', 'like', 'labyrinthine', 'paths', 'through', 'rows', 'of', 'quaint', 'houses', 'adorned', 'with', 'colorful', 'blooms', 'cascading', 'from', 'windowsills', '.']\n",
            "Sentence 3 tokens: ['Each', 'building', 'whispers', 'tales', 'of', 'generations', 'past', ',', 'their', 'facades', 'weathered', 'yet', 'resilient', ',', 'bearing', 'witness', 'to', 'the', 'ebb', 'and', 'flow', 'of', 'life', '.']\n",
            "Sentence 4 tokens: ['In', 'this', 'enclave', 'of', 'tranquility', ',', 'the', 'aroma', 'of', 'freshly', 'baked', 'bread', 'mingles', 'with', 'the', 'scent', 'of', 'blooming', 'jasmine', ',', 'inviting', 'passersby', 'to', 'pause', 'and', 'savor', 'the', 'simple', 'pleasures', '.']\n",
            "Sentence 5 tokens: ['Narrow', 'alleyways', 'beckon', 'the', 'curious', 'to', 'explore', 'hidden', 'courtyards', 'adorned', 'with', 'ivy-covered', 'walls', ',', 'where', 'sunlight', 'filters', 'through', 'ancient', 'trees', ',', 'casting', 'dappled', 'shadows', 'on', 'weathered', 'cobblestones', '.']\n",
            "Sentence 6 tokens: ['Within', 'this', 'enclave', ',', 'a', 'vibrant', 'tapestry', 'of', 'cultures', 'intertwines', ',', 'echoing', 'the', 'harmonious', 'coexistence', 'of', 'its', 'diverse', 'inhabitants', '.']\n",
            "Sentence 7 tokens: ['Here', ',', 'neighbors', 'greet', 'each', 'other', 'with', 'warm', 'smiles', 'and', 'gestures', 'of', 'goodwill', ',', 'fostering', 'a', 'sense', 'of', 'community', 'that', 'transcends', 'boundaries', 'of', 'age', ',', 'ethnicity', ',', 'and', 'creed', '.']\n",
            "Sentence 8 tokens: ['As', 'day', 'turns', 'to', 'dusk', ',', 'the', 'neighborhood', 'comes', 'alive', 'with', 'the', 'gentle', 'hum', 'of', 'conversation', 'and', 'laughter', 'drifting', 'from', 'sidewalk', 'cafes', 'and', 'corner', 'taverns', '.']\n",
            "Sentence 9 tokens: ['Against', 'the', 'backdrop', 'of', 'a', 'painted', 'sky', 'ablaze', 'with', 'hues', 'of', 'orange', 'and', 'pink', ',', 'residents', 'gather', 'to', 'share', 'stories', 'and', 'laughter', ',', 'finding', 'solace', 'in', 'the', 'simple', 'joys', 'of', 'human', 'connection', '.']\n",
            "Sentence 10 tokens: ['In', 'this', 'hidden', 'gem', 'within', 'the', 'city', \"'s\", 'embrace', ',', 'time', 'slows', 'to', 'a', 'gentle', 'rhythm', ',', 'offering', 'sanctuary', 'to', 'weary', 'souls', 'seeking', 'refuge', 'from', 'the', 'frenetic', 'pace', 'of', 'modern', 'life', '.']\n",
            "Sentence 11 tokens: ['Amidst', 'the', 'chaos', 'of', 'the', 'world', 'beyond', 'its', 'borders', ',', 'this', 'neighborhood', 'remains', 'a', 'beacon', 'of', 'serenity', ',', 'a', 'testament', 'to', 'the', 'enduring', 'power', 'of', 'community', 'and', 'the', 'timeless', 'beauty', 'of', 'human', 'connection']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_sentences = []\n",
        "for sentence in sentences:\n",
        "    word_tokens = word_tokenize(sentence)\n",
        "    filtered_sentence = [stemmer.stem(word.lower()) for word in word_tokens if word.lower() not in stop_words]\n",
        "    stemmed_sentences.append(filtered_sentence)\n",
        "\n",
        "# Print the stemmed sentences\n",
        "for i, stemmed_sentence in enumerate(stemmed_sentences, 1):\n",
        "    print(f\"Sentence {i} tokens (stemmed and without stop words):\", stemmed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXXVGACWsNPh",
        "outputId": "7e3bb6f1-d774-41e7-a038-281ac64c58c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 tokens (stemmed and without stop words): ['heart', 'bustl', 'metropoli', 'lie', 'neighborhood', 'time', 'seem', 'stand', 'still', '.']\n",
            "Sentence 2 tokens (stemmed and without stop words): [',', 'cobbleston', 'street', 'wind', 'like', 'labyrinthin', 'path', 'row', 'quaint', 'hous', 'adorn', 'color', 'bloom', 'cascad', 'windowsil', '.']\n",
            "Sentence 3 tokens (stemmed and without stop words): ['build', 'whisper', 'tale', 'gener', 'past', ',', 'facad', 'weather', 'yet', 'resili', ',', 'bear', 'wit', 'ebb', 'flow', 'life', '.']\n",
            "Sentence 4 tokens (stemmed and without stop words): ['enclav', 'tranquil', ',', 'aroma', 'freshli', 'bake', 'bread', 'mingl', 'scent', 'bloom', 'jasmin', ',', 'invit', 'passersbi', 'paus', 'savor', 'simpl', 'pleasur', '.']\n",
            "Sentence 5 tokens (stemmed and without stop words): ['narrow', 'alleyway', 'beckon', 'curiou', 'explor', 'hidden', 'courtyard', 'adorn', 'ivy-cov', 'wall', ',', 'sunlight', 'filter', 'ancient', 'tree', ',', 'cast', 'dappl', 'shadow', 'weather', 'cobbleston', '.']\n",
            "Sentence 6 tokens (stemmed and without stop words): ['within', 'enclav', ',', 'vibrant', 'tapestri', 'cultur', 'intertwin', ',', 'echo', 'harmoni', 'coexist', 'divers', 'inhabit', '.']\n",
            "Sentence 7 tokens (stemmed and without stop words): [',', 'neighbor', 'greet', 'warm', 'smile', 'gestur', 'goodwil', ',', 'foster', 'sens', 'commun', 'transcend', 'boundari', 'age', ',', 'ethnic', ',', 'creed', '.']\n",
            "Sentence 8 tokens (stemmed and without stop words): ['day', 'turn', 'dusk', ',', 'neighborhood', 'come', 'aliv', 'gentl', 'hum', 'convers', 'laughter', 'drift', 'sidewalk', 'cafe', 'corner', 'tavern', '.']\n",
            "Sentence 9 tokens (stemmed and without stop words): ['backdrop', 'paint', 'sky', 'ablaz', 'hue', 'orang', 'pink', ',', 'resid', 'gather', 'share', 'stori', 'laughter', ',', 'find', 'solac', 'simpl', 'joy', 'human', 'connect', '.']\n",
            "Sentence 10 tokens (stemmed and without stop words): ['hidden', 'gem', 'within', 'citi', \"'s\", 'embrac', ',', 'time', 'slow', 'gentl', 'rhythm', ',', 'offer', 'sanctuari', 'weari', 'soul', 'seek', 'refug', 'frenet', 'pace', 'modern', 'life', '.']\n",
            "Sentence 11 tokens (stemmed and without stop words): ['amidst', 'chao', 'world', 'beyond', 'border', ',', 'neighborhood', 'remain', 'beacon', 'seren', ',', 'testament', 'endur', 'power', 'commun', 'timeless', 'beauti', 'human', 'connect']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Sample paragraph\n",
        "paragraph = \"\"\"In the heart of a bustling metropolis lies a neighborhood where time seems to stand still. Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills. Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.\"\"\"\n",
        "\n",
        "# Tokenize the paragraph into sentences\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# Tokenize each sentence into words and remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_sentences = []\n",
        "for sentence in sentences:\n",
        "    word_tokens = word_tokenize(sentence)\n",
        "    filtered_sentence = [lemmatizer.lemmatize(word.lower()) for word in word_tokens if word.lower() not in stop_words]\n",
        "    lemmatized_sentences.append(filtered_sentence)\n",
        "\n",
        "# Print the lemmatized sentences\n",
        "for i, lemmatized_sentence in enumerate(lemmatized_sentences, 1):\n",
        "    print(f\"Sentence {i} tokens (lemmatized and without stop words):\", lemmatized_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vKcJE-_1oJz",
        "outputId": "3d2ae06b-54d2-44af-ec33-0e161cea1ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 tokens (lemmatized and without stop words): ['heart', 'bustling', 'metropolis', 'lie', 'neighborhood', 'time', 'seems', 'stand', 'still', '.']\n",
            "Sentence 2 tokens (lemmatized and without stop words): [',', 'cobblestone', 'street', 'wind', 'like', 'labyrinthine', 'path', 'row', 'quaint', 'house', 'adorned', 'colorful', 'bloom', 'cascading', 'windowsill', '.']\n",
            "Sentence 3 tokens (lemmatized and without stop words): ['building', 'whisper', 'tale', 'generation', 'past', ',', 'facade', 'weathered', 'yet', 'resilient', ',', 'bearing', 'witness', 'ebb', 'flow', 'life', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Sample documents\n",
        "documents =[\"\"\"In the heart of a bustling metropolis lies a neighborhood where time seems to stand still. Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills. Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.\n",
        "\n",
        "In this enclave of tranquility, the aroma of freshly baked bread mingles with the scent of blooming jasmine, inviting passersby to pause and savor the simple pleasures. Narrow alleyways beckon the curious to explore hidden courtyards adorned with ivy-covered walls, where sunlight filters through ancient trees, casting dappled shadows on weathered cobblestones.\n",
        "\n",
        "Within this enclave, a vibrant tapestry of cultures intertwines, echoing the harmonious coexistence of its diverse inhabitants. Here, neighbors greet each other with warm smiles and gestures of goodwill, fostering a sense of community that transcends boundaries of age, ethnicity, and creed.\n",
        "\n",
        "As day turns to dusk, the neighborhood comes alive with the gentle hum of conversation and laughter drifting from sidewalk cafes and corner taverns. Against the backdrop of a painted sky ablaze with hues of orange and pink, residents gather to share stories and laughter, finding solace in the simple joys of human connection.\n",
        "\n",
        "In this hidden gem within the city's embrace, time slows to a gentle rhythm, offering sanctuary to weary souls seeking refuge from the frenetic pace of modern life. Amidst the chaos of the world beyond its borders, this neighborhood remains a beacon of serenity, a testament to the enduring power of community and the timeless beauty of human connection\"\"\"]\n",
        "\n",
        "# Step 1: Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Step 2: Fit and transform the documents to get TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Step 3: Get the feature names (terms)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Step 4: Convert TF-IDF matrix to a dense array for easier manipulation\n",
        "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
        "\n",
        "# Print TF-IDF matrix\n",
        "print(\"TF-IDF Matrix:\")\n",
        "print(tfidf_matrix_dense)\n",
        "\n",
        "# Print feature names\n",
        "print(\"Feature Names:\")\n",
        "print(feature_names)\n",
        "\n",
        "# Optional: Print TF-IDF values for each term in each document\n",
        "for i, doc in enumerate(documents):\n",
        "    print(f\"Document {i+1}:\")\n",
        "    for j, term in enumerate(feature_names):\n",
        "        tfidf_value = tfidf_matrix_dense[i, j]\n",
        "        if tfidf_value != 0:\n",
        "            print(f\"\\t{term}: {tfidf_value:.4f}\")\n"
      ],
      "metadata": {
        "id": "Ls1dneJe6tPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f2b4b9-e3d3-448e-8946-339759910aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix:\n",
            "[[0.02893995 0.05787991 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.26045959 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.05787991\n",
            "  0.05787991 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.05787991 0.02893995 0.02893995 0.02893995 0.05787991\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.08681986 0.02893995\n",
            "  0.02893995 0.02893995 0.05787991 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.05787991 0.05787991 0.02893995 0.02893995\n",
            "  0.02893995 0.05787991 0.11575982 0.02893995 0.02893995 0.02893995\n",
            "  0.05787991 0.02893995 0.02893995 0.02893995 0.02893995 0.05787991\n",
            "  0.02893995 0.05787991 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.08681986 0.02893995 0.60773903 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.05787991 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.49197922 0.02893995 0.11575982 0.05787991\n",
            "  0.05787991 0.02893995 0.26045959 0.02893995 0.02893995 0.02893995\n",
            "  0.02893995 0.02893995 0.02893995 0.02893995 0.02893995 0.05787991\n",
            "  0.05787991 0.02893995 0.02893995 0.02893995 0.17363972 0.05787991\n",
            "  0.02893995 0.02893995 0.02893995]]\n",
            "Feature Names:\n",
            "['ablaze' 'adorned' 'against' 'age' 'alive' 'alleyways' 'amidst' 'ancient'\n",
            " 'and' 'aroma' 'as' 'backdrop' 'baked' 'beacon' 'bearing' 'beauty'\n",
            " 'beckon' 'beyond' 'blooming' 'blooms' 'borders' 'boundaries' 'bread'\n",
            " 'building' 'bustling' 'cafes' 'cascading' 'casting' 'chaos' 'city'\n",
            " 'cobblestone' 'cobblestones' 'coexistence' 'colorful' 'comes' 'community'\n",
            " 'connection' 'conversation' 'corner' 'courtyards' 'covered' 'creed'\n",
            " 'cultures' 'curious' 'dappled' 'day' 'diverse' 'drifting' 'dusk' 'each'\n",
            " 'ebb' 'echoing' 'embrace' 'enclave' 'enduring' 'ethnicity' 'explore'\n",
            " 'facades' 'filters' 'finding' 'flow' 'fostering' 'frenetic' 'freshly'\n",
            " 'from' 'gather' 'gem' 'generations' 'gentle' 'gestures' 'goodwill'\n",
            " 'greet' 'harmonious' 'heart' 'here' 'hidden' 'houses' 'hues' 'hum'\n",
            " 'human' 'in' 'inhabitants' 'intertwines' 'inviting' 'its' 'ivy' 'jasmine'\n",
            " 'joys' 'labyrinthine' 'laughter' 'lies' 'life' 'like' 'metropolis'\n",
            " 'mingles' 'modern' 'narrow' 'neighborhood' 'neighbors' 'of' 'offering'\n",
            " 'on' 'orange' 'other' 'pace' 'painted' 'passersby' 'past' 'paths' 'pause'\n",
            " 'pink' 'pleasures' 'power' 'quaint' 'refuge' 'remains' 'residents'\n",
            " 'resilient' 'rhythm' 'rows' 'sanctuary' 'savor' 'scent' 'seeking' 'seems'\n",
            " 'sense' 'serenity' 'shadows' 'share' 'sidewalk' 'simple' 'sky' 'slows'\n",
            " 'smiles' 'solace' 'souls' 'stand' 'still' 'stories' 'streets' 'sunlight'\n",
            " 'tales' 'tapestry' 'taverns' 'testament' 'that' 'the' 'their' 'this'\n",
            " 'through' 'time' 'timeless' 'to' 'tranquility' 'transcends' 'trees'\n",
            " 'turns' 'vibrant' 'walls' 'warm' 'weary' 'weathered' 'where' 'whispers'\n",
            " 'wind' 'windowsills' 'with' 'within' 'witness' 'world' 'yet']\n",
            "Document 1:\n",
            "\tablaze: 0.0289\n",
            "\tadorned: 0.0579\n",
            "\tagainst: 0.0289\n",
            "\tage: 0.0289\n",
            "\talive: 0.0289\n",
            "\talleyways: 0.0289\n",
            "\tamidst: 0.0289\n",
            "\tancient: 0.0289\n",
            "\tand: 0.2605\n",
            "\taroma: 0.0289\n",
            "\tas: 0.0289\n",
            "\tbackdrop: 0.0289\n",
            "\tbaked: 0.0289\n",
            "\tbeacon: 0.0289\n",
            "\tbearing: 0.0289\n",
            "\tbeauty: 0.0289\n",
            "\tbeckon: 0.0289\n",
            "\tbeyond: 0.0289\n",
            "\tblooming: 0.0289\n",
            "\tblooms: 0.0289\n",
            "\tborders: 0.0289\n",
            "\tboundaries: 0.0289\n",
            "\tbread: 0.0289\n",
            "\tbuilding: 0.0289\n",
            "\tbustling: 0.0289\n",
            "\tcafes: 0.0289\n",
            "\tcascading: 0.0289\n",
            "\tcasting: 0.0289\n",
            "\tchaos: 0.0289\n",
            "\tcity: 0.0289\n",
            "\tcobblestone: 0.0289\n",
            "\tcobblestones: 0.0289\n",
            "\tcoexistence: 0.0289\n",
            "\tcolorful: 0.0289\n",
            "\tcomes: 0.0289\n",
            "\tcommunity: 0.0579\n",
            "\tconnection: 0.0579\n",
            "\tconversation: 0.0289\n",
            "\tcorner: 0.0289\n",
            "\tcourtyards: 0.0289\n",
            "\tcovered: 0.0289\n",
            "\tcreed: 0.0289\n",
            "\tcultures: 0.0289\n",
            "\tcurious: 0.0289\n",
            "\tdappled: 0.0289\n",
            "\tday: 0.0289\n",
            "\tdiverse: 0.0289\n",
            "\tdrifting: 0.0289\n",
            "\tdusk: 0.0289\n",
            "\teach: 0.0579\n",
            "\tebb: 0.0289\n",
            "\techoing: 0.0289\n",
            "\tembrace: 0.0289\n",
            "\tenclave: 0.0579\n",
            "\tenduring: 0.0289\n",
            "\tethnicity: 0.0289\n",
            "\texplore: 0.0289\n",
            "\tfacades: 0.0289\n",
            "\tfilters: 0.0289\n",
            "\tfinding: 0.0289\n",
            "\tflow: 0.0289\n",
            "\tfostering: 0.0289\n",
            "\tfrenetic: 0.0289\n",
            "\tfreshly: 0.0289\n",
            "\tfrom: 0.0868\n",
            "\tgather: 0.0289\n",
            "\tgem: 0.0289\n",
            "\tgenerations: 0.0289\n",
            "\tgentle: 0.0579\n",
            "\tgestures: 0.0289\n",
            "\tgoodwill: 0.0289\n",
            "\tgreet: 0.0289\n",
            "\tharmonious: 0.0289\n",
            "\theart: 0.0289\n",
            "\there: 0.0579\n",
            "\thidden: 0.0579\n",
            "\thouses: 0.0289\n",
            "\thues: 0.0289\n",
            "\thum: 0.0289\n",
            "\thuman: 0.0579\n",
            "\tin: 0.1158\n",
            "\tinhabitants: 0.0289\n",
            "\tintertwines: 0.0289\n",
            "\tinviting: 0.0289\n",
            "\tits: 0.0579\n",
            "\tivy: 0.0289\n",
            "\tjasmine: 0.0289\n",
            "\tjoys: 0.0289\n",
            "\tlabyrinthine: 0.0289\n",
            "\tlaughter: 0.0579\n",
            "\tlies: 0.0289\n",
            "\tlife: 0.0579\n",
            "\tlike: 0.0289\n",
            "\tmetropolis: 0.0289\n",
            "\tmingles: 0.0289\n",
            "\tmodern: 0.0289\n",
            "\tnarrow: 0.0289\n",
            "\tneighborhood: 0.0868\n",
            "\tneighbors: 0.0289\n",
            "\tof: 0.6077\n",
            "\toffering: 0.0289\n",
            "\ton: 0.0289\n",
            "\torange: 0.0289\n",
            "\tother: 0.0289\n",
            "\tpace: 0.0289\n",
            "\tpainted: 0.0289\n",
            "\tpassersby: 0.0289\n",
            "\tpast: 0.0289\n",
            "\tpaths: 0.0289\n",
            "\tpause: 0.0289\n",
            "\tpink: 0.0289\n",
            "\tpleasures: 0.0289\n",
            "\tpower: 0.0289\n",
            "\tquaint: 0.0289\n",
            "\trefuge: 0.0289\n",
            "\tremains: 0.0289\n",
            "\tresidents: 0.0289\n",
            "\tresilient: 0.0289\n",
            "\trhythm: 0.0289\n",
            "\trows: 0.0289\n",
            "\tsanctuary: 0.0289\n",
            "\tsavor: 0.0289\n",
            "\tscent: 0.0289\n",
            "\tseeking: 0.0289\n",
            "\tseems: 0.0289\n",
            "\tsense: 0.0289\n",
            "\tserenity: 0.0289\n",
            "\tshadows: 0.0289\n",
            "\tshare: 0.0289\n",
            "\tsidewalk: 0.0289\n",
            "\tsimple: 0.0579\n",
            "\tsky: 0.0289\n",
            "\tslows: 0.0289\n",
            "\tsmiles: 0.0289\n",
            "\tsolace: 0.0289\n",
            "\tsouls: 0.0289\n",
            "\tstand: 0.0289\n",
            "\tstill: 0.0289\n",
            "\tstories: 0.0289\n",
            "\tstreets: 0.0289\n",
            "\tsunlight: 0.0289\n",
            "\ttales: 0.0289\n",
            "\ttapestry: 0.0289\n",
            "\ttaverns: 0.0289\n",
            "\ttestament: 0.0289\n",
            "\tthat: 0.0289\n",
            "\tthe: 0.4920\n",
            "\ttheir: 0.0289\n",
            "\tthis: 0.1158\n",
            "\tthrough: 0.0579\n",
            "\ttime: 0.0579\n",
            "\ttimeless: 0.0289\n",
            "\tto: 0.2605\n",
            "\ttranquility: 0.0289\n",
            "\ttranscends: 0.0289\n",
            "\ttrees: 0.0289\n",
            "\tturns: 0.0289\n",
            "\tvibrant: 0.0289\n",
            "\twalls: 0.0289\n",
            "\twarm: 0.0289\n",
            "\tweary: 0.0289\n",
            "\tweathered: 0.0579\n",
            "\twhere: 0.0579\n",
            "\twhispers: 0.0289\n",
            "\twind: 0.0289\n",
            "\twindowsills: 0.0289\n",
            "\twith: 0.1736\n",
            "\twithin: 0.0579\n",
            "\twitness: 0.0289\n",
            "\tworld: 0.0289\n",
            "\tyet: 0.0289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define the corpus\n",
        "corpus = \"\"\"\n",
        "In the heart of a bustling metropolis lies a neighborhood where time seems to stand still. Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills. Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.\n",
        "\n",
        "In this enclave of tranquility, the aroma of freshly baked bread mingles with the scent of blooming jasmine, inviting passersby to pause and savor the simple pleasures. Narrow alleyways beckon the curious to explore hidden courtyards adorned with ivy-covered walls, where sunlight filters through ancient trees, casting dappled shadows on weathered cobblestones.\n",
        "\n",
        "Within this enclave, a vibrant tapestry of cultures intertwines, echoing the harmonious coexistence of its diverse inhabitants. Here, neighbors greet each other with warm smiles and gestures of goodwill, fostering a sense of community that transcends boundaries of age, ethnicity, and creed.\n",
        "\n",
        "As day turns to dusk, the neighborhood comes alive with the gentle hum of conversation and laughter drifting from sidewalk cafes and corner taverns. Against the backdrop of a painted sky ablaze with hues of orange and pink, residents gather to share stories and laughter, finding solace in the simple joys of human connection.\n",
        "\n",
        "In this hidden gem within the city's embrace, time slows to a gentle rhythm, offering sanctuary to weary souls seeking refuge from the frenetic pace of modern life. Amidst the chaos of the world beyond its borders, this neighborhood remains a beacon of serenity, a testament to the enduring power of community and the timeless beauty of human connection\n",
        "\"\"\"\n",
        "\n",
        "# Initialize Count Vectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the corpus to get Count Vector\n",
        "count_vector = count_vectorizer.fit_transform([corpus])\n",
        "\n",
        "# Get feature names (terms)\n",
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert Count Vector to a dense array for easier manipulation\n",
        "count_vector_dense = count_vector.toarray()\n",
        "\n",
        "# Create a dictionary to store term frequencies\n",
        "term_freq_dict = {}\n",
        "for i, term in enumerate(feature_names):\n",
        "    term_freq_dict[term] = count_vector_dense[0, i]\n",
        "\n",
        "# Print term frequencies\n",
        "for term, freq in sorted(term_freq_dict.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{term}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbJ-oM5GbChn",
        "outputId": "95117b0f-e1f2-4415-8b05-7f686698ec90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of: 21\n",
            "the: 17\n",
            "and: 9\n",
            "to: 9\n",
            "with: 6\n",
            "in: 4\n",
            "this: 4\n",
            "from: 3\n",
            "neighborhood: 3\n",
            "adorned: 2\n",
            "community: 2\n",
            "connection: 2\n",
            "each: 2\n",
            "enclave: 2\n",
            "gentle: 2\n",
            "here: 2\n",
            "hidden: 2\n",
            "human: 2\n",
            "its: 2\n",
            "laughter: 2\n",
            "life: 2\n",
            "simple: 2\n",
            "through: 2\n",
            "time: 2\n",
            "weathered: 2\n",
            "where: 2\n",
            "within: 2\n",
            "ablaze: 1\n",
            "against: 1\n",
            "age: 1\n",
            "alive: 1\n",
            "alleyways: 1\n",
            "amidst: 1\n",
            "ancient: 1\n",
            "aroma: 1\n",
            "as: 1\n",
            "backdrop: 1\n",
            "baked: 1\n",
            "beacon: 1\n",
            "bearing: 1\n",
            "beauty: 1\n",
            "beckon: 1\n",
            "beyond: 1\n",
            "blooming: 1\n",
            "blooms: 1\n",
            "borders: 1\n",
            "boundaries: 1\n",
            "bread: 1\n",
            "building: 1\n",
            "bustling: 1\n",
            "cafes: 1\n",
            "cascading: 1\n",
            "casting: 1\n",
            "chaos: 1\n",
            "city: 1\n",
            "cobblestone: 1\n",
            "cobblestones: 1\n",
            "coexistence: 1\n",
            "colorful: 1\n",
            "comes: 1\n",
            "conversation: 1\n",
            "corner: 1\n",
            "courtyards: 1\n",
            "covered: 1\n",
            "creed: 1\n",
            "cultures: 1\n",
            "curious: 1\n",
            "dappled: 1\n",
            "day: 1\n",
            "diverse: 1\n",
            "drifting: 1\n",
            "dusk: 1\n",
            "ebb: 1\n",
            "echoing: 1\n",
            "embrace: 1\n",
            "enduring: 1\n",
            "ethnicity: 1\n",
            "explore: 1\n",
            "facades: 1\n",
            "filters: 1\n",
            "finding: 1\n",
            "flow: 1\n",
            "fostering: 1\n",
            "frenetic: 1\n",
            "freshly: 1\n",
            "gather: 1\n",
            "gem: 1\n",
            "generations: 1\n",
            "gestures: 1\n",
            "goodwill: 1\n",
            "greet: 1\n",
            "harmonious: 1\n",
            "heart: 1\n",
            "houses: 1\n",
            "hues: 1\n",
            "hum: 1\n",
            "inhabitants: 1\n",
            "intertwines: 1\n",
            "inviting: 1\n",
            "ivy: 1\n",
            "jasmine: 1\n",
            "joys: 1\n",
            "labyrinthine: 1\n",
            "lies: 1\n",
            "like: 1\n",
            "metropolis: 1\n",
            "mingles: 1\n",
            "modern: 1\n",
            "narrow: 1\n",
            "neighbors: 1\n",
            "offering: 1\n",
            "on: 1\n",
            "orange: 1\n",
            "other: 1\n",
            "pace: 1\n",
            "painted: 1\n",
            "passersby: 1\n",
            "past: 1\n",
            "paths: 1\n",
            "pause: 1\n",
            "pink: 1\n",
            "pleasures: 1\n",
            "power: 1\n",
            "quaint: 1\n",
            "refuge: 1\n",
            "remains: 1\n",
            "residents: 1\n",
            "resilient: 1\n",
            "rhythm: 1\n",
            "rows: 1\n",
            "sanctuary: 1\n",
            "savor: 1\n",
            "scent: 1\n",
            "seeking: 1\n",
            "seems: 1\n",
            "sense: 1\n",
            "serenity: 1\n",
            "shadows: 1\n",
            "share: 1\n",
            "sidewalk: 1\n",
            "sky: 1\n",
            "slows: 1\n",
            "smiles: 1\n",
            "solace: 1\n",
            "souls: 1\n",
            "stand: 1\n",
            "still: 1\n",
            "stories: 1\n",
            "streets: 1\n",
            "sunlight: 1\n",
            "tales: 1\n",
            "tapestry: 1\n",
            "taverns: 1\n",
            "testament: 1\n",
            "that: 1\n",
            "their: 1\n",
            "timeless: 1\n",
            "tranquility: 1\n",
            "transcends: 1\n",
            "trees: 1\n",
            "turns: 1\n",
            "vibrant: 1\n",
            "walls: 1\n",
            "warm: 1\n",
            "weary: 1\n",
            "whispers: 1\n",
            "wind: 1\n",
            "windowsills: 1\n",
            "witness: 1\n",
            "world: 1\n",
            "yet: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define the corpus\n",
        "corpus = [\n",
        "   \"\"\"\n",
        "In the heart of a bustling metropolis lies a neighborhood where time seems to stand still. Here, cobblestone streets wind like labyrinthine paths through rows of quaint houses adorned with colorful blooms cascading from windowsills. Each building whispers tales of generations past, their facades weathered yet resilient, bearing witness to the ebb and flow of life.\n",
        "\n",
        "In this enclave of tranquility, the aroma of freshly baked bread mingles with the scent of blooming jasmine, inviting passersby to pause and savor the simple pleasures. Narrow alleyways beckon the curious to explore hidden courtyards adorned with ivy-covered walls, where sunlight filters through ancient trees, casting dappled shadows on weathered cobblestones.\n",
        "\n",
        "Within this enclave, a vibrant tapestry of cultures intertwines, echoing the harmonious coexistence of its diverse inhabitants. Here, neighbors greet each other with warm smiles and gestures of goodwill, fostering a sense of community that transcends boundaries of age, ethnicity, and creed.\n",
        "\n",
        "As day turns to dusk, the neighborhood comes alive with the gentle hum of conversation and laughter drifting from sidewalk cafes and corner taverns. Against the backdrop of a painted sky ablaze with hues of orange and pink, residents gather to share stories and laughter, finding solace in the simple joys of human connection.\n",
        "\n",
        "In this hidden gem within the city's embrace, time slows to a gentle rhythm, offering sanctuary to weary souls seeking refuge from the frenetic pace of modern life. Amidst the chaos of the world beyond its borders, this neighborhood remains a beacon of serenity, a testament to the enduring power of community and the timeless beauty of human connection\n",
        "\"\"\"\n",
        "]\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the corpus and transform the documents\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the Bag of Words matrix to a dense array for easier manipulation\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# Print the feature names and Bag of Words matrix\n",
        "print(\"Feature Names:\")\n",
        "print(feature_names)\n",
        "\n",
        "print(\"\\nBag of Words Matrix:\")\n",
        "print(X_dense)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RanC4iXed2Y",
        "outputId": "65dd41d9-d574-45c4-996b-4533add2e34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names:\n",
            "['ablaze' 'adorned' 'against' 'age' 'alive' 'alleyways' 'amidst' 'ancient'\n",
            " 'and' 'aroma' 'as' 'backdrop' 'baked' 'beacon' 'bearing' 'beauty'\n",
            " 'beckon' 'beyond' 'blooming' 'blooms' 'borders' 'boundaries' 'bread'\n",
            " 'building' 'bustling' 'cafes' 'cascading' 'casting' 'chaos' 'city'\n",
            " 'cobblestone' 'cobblestones' 'coexistence' 'colorful' 'comes' 'community'\n",
            " 'connection' 'conversation' 'corner' 'courtyards' 'covered' 'creed'\n",
            " 'cultures' 'curious' 'dappled' 'day' 'diverse' 'drifting' 'dusk' 'each'\n",
            " 'ebb' 'echoing' 'embrace' 'enclave' 'enduring' 'ethnicity' 'explore'\n",
            " 'facades' 'filters' 'finding' 'flow' 'fostering' 'frenetic' 'freshly'\n",
            " 'from' 'gather' 'gem' 'generations' 'gentle' 'gestures' 'goodwill'\n",
            " 'greet' 'harmonious' 'heart' 'here' 'hidden' 'houses' 'hues' 'hum'\n",
            " 'human' 'in' 'inhabitants' 'intertwines' 'inviting' 'its' 'ivy' 'jasmine'\n",
            " 'joys' 'labyrinthine' 'laughter' 'lies' 'life' 'like' 'metropolis'\n",
            " 'mingles' 'modern' 'narrow' 'neighborhood' 'neighbors' 'of' 'offering'\n",
            " 'on' 'orange' 'other' 'pace' 'painted' 'passersby' 'past' 'paths' 'pause'\n",
            " 'pink' 'pleasures' 'power' 'quaint' 'refuge' 'remains' 'residents'\n",
            " 'resilient' 'rhythm' 'rows' 'sanctuary' 'savor' 'scent' 'seeking' 'seems'\n",
            " 'sense' 'serenity' 'shadows' 'share' 'sidewalk' 'simple' 'sky' 'slows'\n",
            " 'smiles' 'solace' 'souls' 'stand' 'still' 'stories' 'streets' 'sunlight'\n",
            " 'tales' 'tapestry' 'taverns' 'testament' 'that' 'the' 'their' 'this'\n",
            " 'through' 'time' 'timeless' 'to' 'tranquility' 'transcends' 'trees'\n",
            " 'turns' 'vibrant' 'walls' 'warm' 'weary' 'weathered' 'where' 'whispers'\n",
            " 'wind' 'windowsills' 'with' 'within' 'witness' 'world' 'yet']\n",
            "\n",
            "Bag of Words Matrix:\n",
            "[[ 1  2  1  1  1  1  1  1  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "   1  1  1  1  1  1  1  1  1  1  1  2  2  1  1  1  1  1  1  1  1  1  1  1\n",
            "   1  2  1  1  1  2  1  1  1  1  1  1  1  1  1  1  3  1  1  1  2  1  1  1\n",
            "   1  1  2  2  1  1  1  2  4  1  1  1  2  1  1  1  1  2  1  2  1  1  1  1\n",
            "   1  3  1 21  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "   1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "   1  1 17  1  4  2  2  1  9  1  1  1  1  1  1  1  1  2  2  1  1  1  6  2\n",
            "   1  1  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4SjRqVBe2IL",
        "outputId": "0c8195b3-ab0f-4258-d42e-142efb95e1f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "VAipShRkvwix",
        "outputId": "6b0519a1-8a6f-4239-f5c4-71dcb64a0cc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-723977d5-fff3-4481-a1d8-649500855aea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-723977d5-fff3-4481-a1d8-649500855aea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SMSSpamCollection to SMSSpamCollection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "wjF6PmlRv-B4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"SMSSpamCollection\",sep=\"\\t\",names=[\"label\",\"message\"])"
      ],
      "metadata": {
        "id": "lKBqUDsIwMO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5d2c279c-bfe7-4988-bc73-e8a03c241d0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label                                            message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c36c5ae8-94ae-4d37-9c51-ac79b4116097\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c36c5ae8-94ae-4d37-9c51-ac79b4116097')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c36c5ae8-94ae-4d37-9c51-ac79b4116097 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c36c5ae8-94ae-4d37-9c51-ac79b4116097');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f58f954-2190-45cc-93cb-26891af677fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f58f954-2190-45cc-93cb-26891af677fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f58f954-2190-45cc-93cb-26891af677fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Ensure you have the necessary NLTK datasets\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"message\"])\n",
        "\n",
        "# Function to clean text data\n",
        "def clean_text(text):\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Remove non-alphabetic characters\n",
        "    tokens = [token for token in tokens if token.isalpha()]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if not token in stop_words]\n",
        "\n",
        "    # Optional: Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Join words back to string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the cleaning function to each message\n",
        "df['message_clean'] = df['message'].apply(clean_text)\n",
        "\n",
        "# View the cleaned data\n",
        "print(df.head())\n",
        "\n",
        "# Optionally save the cleaned data\n",
        "df.to_csv(\"SMSSpamCollection_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlsM1KhZX_FW",
        "outputId": "29c3ccc2-11ee-49dd-8dbf-549430c97eea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...   \n",
            "1   ham                      Ok lar... Joking wif u oni...   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3   ham  U dun say so early hor... U c already then say...   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                       message_clean  \n",
            "0  go jurong point crazi avail bugi n great world...  \n",
            "1                              ok lar joke wif u oni  \n",
            "2  free entri wkli comp win fa cup final tkt may ...  \n",
            "3                u dun say earli hor u c alreadi say  \n",
            "4               nah think goe usf live around though  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"SMSSpamCollection_cleaned.csv\")\n",
        "\n",
        "# Check for NaN values and handle them\n",
        "if df['message_clean'].isnull().any():\n",
        "    print(\"NaN values found. Filling NaNs with empty string.\")\n",
        "    df['message_clean'] = df['message_clean'].fillna('')  # Fill NaNs with empty string\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the model and transform the data\n",
        "X = vectorizer.fit_transform(df['message_clean'])\n",
        "\n",
        "# View the shape of the matrix\n",
        "print(X.shape)  # This will print the shape of the matrix (n_documents, n_features)\n",
        "\n",
        "# Include the labels for model training\n",
        "y = df['label'].apply(lambda x: 1 if x == 'spam' else 0)  # Encoding 'spam' as 1 and 'ham' as 0\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f09DooqKY5so",
        "outputId": "c9c67090-1748-4bbd-fb39-9fe8eecda1f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values found. Filling NaNs with empty string.\n",
            "(5572, 5905)\n",
            "Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"SMSSpamCollection_cleaned.csv\")\n",
        "\n",
        "# Check for NaN values and handle them\n",
        "if df['message_clean'].isnull().any():\n",
        "    print(\"NaN values found. Filling NaNs with empty string.\")\n",
        "    df['message_clean'] = df['message_clean'].fillna('')  # Fill NaNs with empty string\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the model and transform the data\n",
        "X = tfidf_vectorizer.fit_transform(df['message_clean'])\n",
        "\n",
        "# View the shape of the matrix\n",
        "print(X.shape)  # This will print the shape of the matrix (n_documents, n_features)\n",
        "\n",
        "# Include the labels for model training\n",
        "y = df['label'].apply(lambda x: 1 if x == 'spam' else 0)  # Encoding 'spam' as 1 and 'ham' as 0\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlI6id8nZU2P",
        "outputId": "0a6f5743-f735-4ac0-a630-f5712ff55ee8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values found. Filling NaNs with empty string.\n",
            "(5572, 5905)\n",
            "Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hihxS58dhBsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}